{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ycqMSLnkZkGD"
      },
      "source": [
        "### LSTM"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cQhY8OWpZkGG"
      },
      "source": [
        "Long Short-Term Memory (LSTM) networks are a type of recurrent neural network capable of learning order dependence in sequence prediction problems.|"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "ZyghfuDYZ6DO"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DhfqScAKZkGH"
      },
      "source": [
        "<img src=\"https://miro.medium.com/max/840/1*yBXV9o5q7L_CvY7quJt3WQ.png\">\n",
        "\n",
        "These gates can learn which data in a sequence is important to keep or throw away. By doing that, it can pass relevant information down the long chain of sequences to make predictions. Almost all state of the art results based on recurrent neural networks are achieved with these two networks. LSTM’s and GRU’s can be found in speech recognition, speech synthesis, and text generation. You can even use them to generate captions for videos\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vw4MOYFOZkGH"
      },
      "source": [
        "# Data Loading"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0rWs7TbGZkGI"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas_datareader as web\n",
        "from datetime import datetime\n",
        "import math"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install upgrade pandas\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Oy7ps54PfDgW",
        "outputId": "790eadf7-f687-45ab-81f4-9149568902fd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[31mERROR: Could not find a version that satisfies the requirement upgrade (from versions: none)\u001b[0m\n",
            "\u001b[31mERROR: No matching distribution found for upgrade\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install upgrade pandas-datareader"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qlSo1EzzfPc4",
        "outputId": "c51d21a8-ffd4-4593-bb53-623418ddf1a1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[31mERROR: Could not find a version that satisfies the requirement upgrade (from versions: none)\u001b[0m\n",
            "\u001b[31mERROR: No matching distribution found for upgrade\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 502
        },
        "id": "0IEIk0ixZkGI",
        "outputId": "502288fe-0677-4371-9976-c8d927c8a70f"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "RemoteDataError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRemoteDataError\u001b[0m                           Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-f4911201acce>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2015\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2021\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m12\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m31\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mNVDA\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'NVDA'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'yahoo'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mNVDA\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    205\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m                     \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnew_arg_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_arg_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 207\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    208\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    209\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas_datareader/data.py\u001b[0m in \u001b[0;36mDataReader\u001b[0;34m(name, data_source, start, end, retry_count, pause, session, api_key)\u001b[0m\n\u001b[1;32m    382\u001b[0m             \u001b[0mretry_count\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mretry_count\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    383\u001b[0m             \u001b[0mpause\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpause\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 384\u001b[0;31m             \u001b[0msession\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    385\u001b[0m         ).read()\n\u001b[1;32m    386\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas_datareader/base.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    251\u001b[0m         \u001b[0;31m# If a single symbol, (e.g., 'GOOG')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msymbols\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mstring_types\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 253\u001b[0;31m             \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_read_one_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msymbols\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    254\u001b[0m         \u001b[0;31m# Or multiple symbols, (e.g., ['GOOG', 'AAPL', 'MSFT'])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msymbols\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas_datareader/yahoo/daily.py\u001b[0m in \u001b[0;36m_read_one_data\u001b[0;34m(self, url, params)\u001b[0m\n\u001b[1;32m    151\u001b[0m         \u001b[0murl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msymbol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m         \u001b[0mresp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    154\u001b[0m         \u001b[0mptrn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mr\"root\\.App\\.main = (.*?);\\n}\\(this\\)\\);\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas_datareader/base.py\u001b[0m in \u001b[0;36m_get_response\u001b[0;34m(self, url, params, headers)\u001b[0m\n\u001b[1;32m    179\u001b[0m             \u001b[0mmsg\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"\\nResponse Text:\\n{0}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlast_response_text\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 181\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mRemoteDataError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    182\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_crumb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRemoteDataError\u001b[0m: Unable to read URL: https://finance.yahoo.com/quote/NVDA/history?period1=1420084800&period2=1641009599&interval=1d&frequency=1d&filter=history\nResponse Text:\nb'<!DOCTYPE html>\\n  <html lang=\"en-us\"><head>\\n  <meta http-equiv=\"content-type\" content=\"text/html; charset=UTF-8\">\\n      <meta charset=\"utf-8\">\\n      <title>Yahoo</title>\\n      <meta name=\"viewport\" content=\"width=device-width,initial-scale=1,minimal-ui\">\\n      <meta http-equiv=\"X-UA-Compatible\" content=\"IE=edge,chrome=1\">\\n      <style>\\n  html {\\n      height: 100%;\\n  }\\n  body {\\n      background: #fafafc url(https://s.yimg.com/nn/img/sad-panda-201402200631.png) 50% 50%;\\n      background-size: cover;\\n      height: 100%;\\n      text-align: center;\\n      font: 300 18px \"helvetica neue\", helvetica, verdana, tahoma, arial, sans-serif;\\n  }\\n  table {\\n      height: 100%;\\n      width: 100%;\\n      table-layout: fixed;\\n      border-collapse: collapse;\\n      border-spacing: 0;\\n      border: none;\\n  }\\n  h1 {\\n      font-size: 42px;\\n      font-weight: 400;\\n      color: #400090;\\n  }\\n  p {\\n      color: #1A1A1A;\\n  }\\n  #message-1 {\\n      font-weight: bold;\\n      margin: 0;\\n  }\\n  #message-2 {\\n      display: inline-block;\\n      *display: inline;\\n      zoom: 1;\\n      max-width: 17em;\\n      _width: 17em;\\n  }\\n      </style>\\n  <script>\\n    document.write(\\'<img src=\"//geo.yahoo.com/b?s=1197757129&t=\\'+new Date().getTime()+\\'&src=aws&err_url=\\'+encodeURIComponent(document.URL)+\\'&err=%<pssc>&test=\\'+encodeURIComponent(\\'%<{Bucket}cqh[:200]>\\')+\\'\" width=\"0px\" height=\"0px\"/>\\');var beacon = new Image();beacon.src=\"//bcn.fp.yahoo.com/p?s=1197757129&t=\"+ne..."
          ]
        }
      ],
      "source": [
        "#Loading Data\n",
        "start = datetime(2015, 1, 1)\n",
        "end = datetime(2021, 12, 31)\n",
        "NVDA = web.DataReader('NVDA', 'yahoo', start, end)\n",
        "NVDA.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XWV_5qCXZkGJ"
      },
      "outputs": [],
      "source": [
        "#visualize the closing price hostory\n",
        "plt.figure(figsize=(14,14))\n",
        "plt.plot(NVDA['Close'])\n",
        "plt.title('Closing Price History')\n",
        "plt.xlabel('Date')\n",
        "plt.ylabel('Stock Close Price USD $')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cGEerf6IZkGK"
      },
      "outputs": [],
      "source": [
        "df1=NVDA.reset_index()['Close']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0qazh8WFZkGK"
      },
      "outputs": [],
      "source": [
        "df1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U61XDvQqZkGL"
      },
      "source": [
        "### LSTM are sensitive to the scale of the data. so we apply MinMax scaler "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ONFPsamnZkGL"
      },
      "outputs": [],
      "source": [
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7e1xGxWkZkGM"
      },
      "outputs": [],
      "source": [
        "df1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0vjP3scBZkGM"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "scaler=MinMaxScaler(feature_range=(0,1))\n",
        "df1=scaler.fit_transform(np.array(df1).reshape(-1,1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hvl_yjWEZkGM"
      },
      "outputs": [],
      "source": [
        "print(df1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mH_soZdVZkGN"
      },
      "source": [
        "# Splitting dataset into train and test split\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J1yWBonNZkGN"
      },
      "outputs": [],
      "source": [
        "training_size=int(len(df1)*0.65)\n",
        "test_size=len(df1)-training_size\n",
        "train_data,test_data=df1[0:training_size,:],df1[training_size:len(df1),:1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s7oj3HhIZkGN"
      },
      "outputs": [],
      "source": [
        "training_size,test_size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KoyBmCBoZkGN"
      },
      "outputs": [],
      "source": [
        "train_data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lLX02Mq9ZkGO"
      },
      "source": [
        "# Train Test Split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5LbjoJw5ZkGO"
      },
      "outputs": [],
      "source": [
        "import numpy\n",
        "# convert an array of values into a dataset matrix\n",
        "def create_dataset(dataset, time_step=1):\n",
        "\tdataX, dataY = [], []\n",
        "\tfor i in range(len(dataset)-time_step-1):\n",
        "\t\ta = dataset[i:(i+time_step), 0]   ###i=0, 0,1,2,3-----99   100 \n",
        "\t\tdataX.append(a)\n",
        "\t\tdataY.append(dataset[i + time_step, 0])\n",
        "\treturn numpy.array(dataX), numpy.array(dataY)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XoVrCvGfZkGO"
      },
      "outputs": [],
      "source": [
        "# reshape into X=t,t+1,t+2,t+3 and Y=t+4\n",
        "time_step = 100\n",
        "X_train, y_train = create_dataset(train_data, time_step)\n",
        "X_test, ytest = create_dataset(test_data, time_step)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nh5a48yiZkGP"
      },
      "outputs": [],
      "source": [
        "print(X_train.shape), print(y_train.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g_hMF_jXZkGP"
      },
      "outputs": [],
      "source": [
        "print(X_test.shape), print(ytest.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RgLnTPxAZkGQ"
      },
      "outputs": [],
      "source": [
        "# reshape input to be [samples, time steps, features] which is required for LSTM\n",
        "X_train =X_train.reshape(X_train.shape[0],X_train.shape[1] , 1)\n",
        "X_test = X_test.reshape(X_test.shape[0],X_test.shape[1] , 1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zg2Z0GIEZkGQ"
      },
      "source": [
        "### Stacked LSTM model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mo2BcbjNZkGQ"
      },
      "outputs": [],
      "source": [
        "!pip install tensorflow\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.layers import LSTM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e8NvcjhZZkGQ"
      },
      "outputs": [],
      "source": [
        "model=Sequential()\n",
        "model.add(LSTM(50,return_sequences=True,input_shape=(100,1))) #input layer\n",
        "model.add(LSTM(50,return_sequences=True)) #dense layer\n",
        "model.add(LSTM(50)) #dense layer\n",
        "model.add(Dense(1)) #output layer\n",
        "model.compile(loss='mean_squared_error',optimizer='adam')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZvC16SkrZkGR"
      },
      "outputs": [],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NbetDjs2ZkGR"
      },
      "source": [
        "# Training Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tbiXpqJ-ZkGR"
      },
      "outputs": [],
      "source": [
        "model.fit(X_train,y_train,validation_data=(X_test,ytest),epochs=100,batch_size=64,verbose=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hidC03RBZkGR"
      },
      "outputs": [],
      "source": [
        "### Lets Do the prediction and check performance metrics\n",
        "train_predict=model.predict(X_train)\n",
        "test_predict=model.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l8_7AYAZZkGR"
      },
      "outputs": [],
      "source": [
        "##Transformback to original form\n",
        "train_predict=scaler.inverse_transform(train_predict)\n",
        "test_predict=scaler.inverse_transform(test_predict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_8R34373ZkGS"
      },
      "outputs": [],
      "source": [
        "### Calculate RMSE performance metrics\n",
        "import math\n",
        "from sklearn.metrics import mean_squared_error\n",
        "math.sqrt(mean_squared_error(y_train,train_predict))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rGiuWrRpZkGS"
      },
      "outputs": [],
      "source": [
        "### Test Data RMSE\n",
        "math.sqrt(mean_squared_error(ytest,test_predict))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V5Zq9I4xZkGS"
      },
      "outputs": [],
      "source": [
        "### Plotting \n",
        "# shift train predictions for plotting\n",
        "look_back=100\n",
        "trainPredictPlot = numpy.empty_like(df1)\n",
        "trainPredictPlot[:, :] = np.nan\n",
        "trainPredictPlot[look_back:len(train_predict)+look_back, :] = train_predict\n",
        "\n",
        "# shift test predictions for plotting\n",
        "testPredictPlot = numpy.empty_like(df1)\n",
        "testPredictPlot[:, :] = numpy.nan\n",
        "testPredictPlot[len(train_predict)+(look_back*2)+1:len(df1)-1, :] = test_predict\n",
        "\n",
        "# plot baseline and predictions\n",
        "plt.title('Closing Price History')\n",
        "plt.xlabel('Date')\n",
        "plt.ylabel('Stock Close Price USD $')\n",
        "plt.plot(scaler.inverse_transform(df1))\n",
        "plt.plot(trainPredictPlot)\n",
        "plt.plot(testPredictPlot)\n",
        "plt.legend(['Original','Train','Validation'],loc='lower right')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zhNINbc3ZkGT"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}